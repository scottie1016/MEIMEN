import streamlit as st
import google.generativeai as genai

# --- 1. è¨­å®šé é¢é…ç½® ---
st.set_page_config(page_title="æˆ‘çš„ Q&A åŠ©æ‰‹", page_icon="ğŸ¤–")

# --- 2. è®€å– API Key (å¾ Streamlit Secrets å®‰å…¨è®€å–) ---
# æ³¨æ„ï¼šæœ¬æ©Ÿæ¸¬è©¦æ™‚ï¼Œè‹¥æ²’æœ‰è¨­å®š secretsï¼Œæœƒå ±éŒ¯ã€‚å»ºè­°ç›´æ¥éƒ¨ç½²åˆ° Streamlit Cloud è¨­å®šã€‚
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
except Exception as e:
    st.error("æ‰¾ä¸åˆ° API Keyï¼Œè«‹æª¢æŸ¥ Streamlit çš„ Secrets è¨­å®šã€‚")
    st.stop()

# --- 3. å®šç¾©ä½ çš„ Q&A è³‡æ–™ (çŸ¥è­˜åº«) ---
# æŠ€å·§ï¼šå¦‚æœæ˜¯ç°¡å–®çš„å•ç­”ï¼Œç›´æ¥è²¼åœ¨é€™è£¡æœ€å¿«ã€‚
# å¦‚æœè³‡æ–™è¶…é 50 é¡Œï¼Œå»ºè­°å¦å¤–ç”¨è®€å– txt æª”æ¡ˆçš„æ–¹å¼ã€‚
qa_knowledge_base = """
Q: å…¬å¸çš„ç‡Ÿæ¥­æ™‚é–“æ˜¯å¹¾é»ï¼Ÿ
A: æˆ‘å€‘é€±ä¸€è‡³é€±äº”æ—©ä¸Š 9:00 åˆ°ä¸‹åˆ 6:00 ç‡Ÿæ¥­ï¼Œåœ‹å®šå‡æ—¥ä¼‘æ¯ã€‚

Q: å•†å“å¯ä»¥é€€è²¨å—ï¼Ÿ
A: æ˜¯çš„ï¼Œè³¼è²·å¾Œ 7 å¤©å…§ä¿æŒåŒ…è£å®Œæ•´çš†å¯é€€è²¨ã€‚è«‹è¯ç¹«å®¢æœä¿¡ç®± service@example.comã€‚

Q: ä½ å€‘æœ‰æä¾›æµ·å¤–é‹é€å—ï¼Ÿ
A: ç›®å‰åƒ…æä¾›å°ç£æœ¬å³¶èˆ‡é›¢å³¶çš„é‹é€æœå‹™ï¼Œæµ·å¤–æš«æœªé–‹æ”¾ã€‚

(è«‹åœ¨æ­¤è™•ç¹¼çºŒè²¼ä¸Šæ‚¨æ”¶é›†å¥½çš„ Q&A...)
"""

# --- 4. è¨­å®š AI æ¨¡å‹èˆ‡ç³»çµ±æŒ‡ä»¤ ---
# ä½¿ç”¨ gemini-1.5-flashï¼Œé€Ÿåº¦å¿«ä¸”å…è²»é¡åº¦é«˜
sys_instruction = f"""
ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„å•ç­”åŠ©æ‰‹ã€‚ä½ çš„ä»»å‹™æ˜¯ã€Œåš´æ ¼æ ¹æ“šã€ä»¥ä¸‹çš„è³‡æ–™åº«å›ç­”ä½¿ç”¨è€…çš„å•é¡Œã€‚

è¦å‰‡ï¼š
1. åªèƒ½ä½¿ç”¨è³‡æ–™åº«å…§çš„è³‡è¨Šï¼Œä¸è¦è‡ªå·±ç·¨é€ æˆ–è¯ç¶²æœå°‹ã€‚
2. å¦‚æœä½¿ç”¨è€…çš„å•é¡Œåœ¨è³‡æ–™åº«ä¸­æ‰¾ä¸åˆ°ç­”æ¡ˆï¼Œè«‹ç›´æ¥å›ç­”ï¼šã€Œä¸å¥½æ„æ€ï¼Œç›®å‰çš„è³‡æ–™åº«ä¸­æ²’æœ‰ç›¸é—œè³‡è¨Šï¼Œå»ºè­°æ‚¨ç›´æ¥è¯ç¹«äººå·¥å®¢æœã€‚ã€
3. å›ç­”è¦è¦ªåˆ‡ã€ç°¡æ½”ã€‚

è³‡æ–™åº«å…§å®¹ï¼š
{qa_knowledge_base}
"""

model = genai.GenerativeModel(
    model_name="gemini-1.5-flash",
    system_instruction=sys_instruction
)

# --- 5. å»ºç«‹èŠå¤©ä»‹é¢ ---
st.title("ğŸ¤– å°ˆå±¬ Q&A çŸ¥è­˜åº«")
st.caption("è«‹è¼¸å…¥å•é¡Œï¼Œæˆ‘æœƒæ ¹æ“šå·²æœ‰çš„è³‡æ–™åº«å›ç­”æ‚¨ã€‚")

# åˆå§‹åŒ–èŠå¤©ç´€éŒ„
if "messages" not in st.session_state:
    st.session_state.messages = []

# é¡¯ç¤ºéå»çš„å°è©±
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# æ¥æ”¶ä½¿ç”¨è€…è¼¸å…¥
if prompt := st.chat_input("è«‹å•æœ‰ä»€éº¼æˆ‘å¯ä»¥å¹«æ‚¨çš„ï¼Ÿ"):
    # 1. é¡¯ç¤ºä½¿ç”¨è€…å•é¡Œ
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # 2. å‘¼å« Gemini ç”Ÿæˆå›ç­”
    try:
        response = model.generate_content(prompt)
        answer = response.text
    except Exception as e:
        answer = "ç³»çµ±å¿™ç¢Œä¸­ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
    
    # 3. é¡¯ç¤º AI å›ç­”
    with st.chat_message("assistant"):
        st.markdown(answer)
    st.session_state.messages.append({"role": "assistant", "content": answer})